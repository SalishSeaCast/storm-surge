Reviewer: 1

Comments to the Author
This manuscript describes the development and evaluation of a 3D baroclinic storm surge model for the Salish Sea. The model is NEMO, the spatial resolution ranges between 440 and 500m and it is run with tidal, and atmospheric, and freshwater discharge forcing.  Tidal model harmonics are compared with counterparts from tide gauge observations and five storm surge events are simulated and compared with sea level observations using several statistical metrics. The relative importance of each of the forcing mechanisms is also investigated. In general, this is solid manuscript that should be published after revisions in accordance with (or rebuttals to) the following comments.


1.	Page 6, lines 20-22: What are the coastline depths? Given that wetting and drying is not included, did you impose a minimum depth to avoid grid cells becoming dry at low tide?
Easy to add

2.	Page 6, lines 24-26: Do you mean the first 10 grid cells inward from the open boundary? From Fig 1 it seems that the cross-strait bathymetry is realistic.
Add clarification in text

3.	Page 6, lines 33-37: Even with this relatively fine spatial resolution, I suspect several compromises were necessary in narrow passages between islands (e.g., Active and Porlier Passes, channels in the Discovery Islands) and perhaps in the mudflat regions around Tsawwassen and Boundary Bay. I would like to see the grid and coastline in some of these regions to determine how well some of the lesser channels and shallow regions have been represented, and some comments on how this might affect the results. Are there plans for nested grids in some of these regions?
Zoom in of Haro Strait and south SoG  added to domain figure. Yes plans for nested grids. Comments about closure of Active Pass to be included in article.

4.	Page 7, lines 54-56: Why not all the other 6, versus just S2 and O1? Could you not obtain and do a t_tide analysis on the observations to get the other 4? Though I suppose that with the tuning, it doesn’t really matter.
Didn't have the observations for the other 6... Clarify in text

5.	Page 8, line 26: Uniform is a reasonable first approximation but I suspect there is a variation. In particular, given the importance of the surge signal coming in from the ocean a geostrophic slope may be a better approximation; though I appreciate there are limited data to estimate it. You might look at old time series with tide gauge observations at both Port Renfrew (or perhaps Bamfield as it is closer to your northern boundary) and Neah Bay. I believe these stations have now been geo-referenced.
Can we demonstrate the the outer surge is large scale and this spatial variation doesn't matter in SoG? Determine velocities of surge and a geostrphic adjustment. Run the model with this to see if it makes a difference.

6.	Page 8, line 46: I think Fig 1 should be extended westward so Port Hardy can be shown.
Add.

7.	Page 9, line 5: Isn’t there also an estuarine flow in Johnstone Strait (Thomson & Huggett)? I don’t think the baroclinic velocities here should be zero.
Comment that the volume is so small we think it is unimportant?

8.	Page 9, line 10-26: Have you done any runs to gauge the sensitivity to these parameters? The background vertical viscosity seems high. Would 10^-5 or 10^-6 make much difference?
No, but trying in the 2D model.

9.	Page 10, line 50: Surface “air” temperature or SST of the nearby ocean?
SST of nearby ocean. Clarify.

10.	Page 11, line 24: You could also note that the dip (another region with partial destructive interference) in the M2 amplitudes around stations 25-26 has also been captured reasonably well.
To be added

11.	Page 13, lines 14-16. I appreciate that this correction was necessary to provide a fairer comparison between the observed and modelled heights at tide gauge locations. But in actual predictions, what will you do to estimate the missing tidal energy at other locations? I would also like to see a few more details on how this correction was computed as there are some subtleties you need to be aware of. Did you analyse the tide gauge record (for the previous year as indicated on line 46-48) for all constituents, reconstruct the tidal content during the surge period with both all constituents and just the big 8, compute the difference, and then add this difference to the model values? If so, this is not quite correct because nonlinear interactions among the big 8 in your model runs will put energy into other constituents like M4, M6, and Msf.  The predicted difference will also include some of this energy so by adding the difference to the model values you now have it twice. Granted this nonlinear energy should be relatively small and you could try to correct for it in the difference. But probably the best solution is to use more constituents in your boundary forcing so there is no need for a correction. I believe Pat Crean used over 60.
So much tuning for K2 etc, that I don't think we should bother forcing with all the constituents. Can I justify that the contributions from the nonlinear components in the model are small? What about the comment on predictions at other locations? Presumably we would need some tidal information to generate water level predictions for other locations (at least Z0)...

12.	Page 13, lines 20-26: I’m not clear on what you did here and why. Did the “long term mean sea level” come from an analysis of tide gauge data – i.e., the Z0 “constituent”? Long term mean modelled sea surface heights over the grid are really relative to one another; they need not be zero. Please clarify.
Need to look at more closely...

13.	Page 13, lines 44-46: Do your tidal predictions include low frequency constituents like Sa, SSa, Mm which likely contain nontidal energy that may vary from year to year?  I appreciate that you didn’t want the presence of the surge to impact the tidal analysis & prediction and that may be why you didn’t base the prediction on a t_tide analysis of the year with the surge. But by not analysing the same year, your predictions and residuals may include contributions that are due to inter-annual variability. I suggest blanking out the surge sections and analysing the same year.
Yes, the tidal predictions did contain Sa, etc. Our response to this comment could lead to rerunning all of the simulations possibly using the CHS constituents. But is this needed? Can I redo forcing residuals without nonlinear constituents?

14.	Page 14: All these statistics provide reasonable measures of mean model performance over specific time periods.  But for storm surges, I think the most important things to know (forecast) are the peak height and the time of this peak. (These are what CHS publishes for the tides in its Tide Tables.) I would therefore like to also see error statistics on these.
Can add this since it is all printed in the tables.

15.	Page 15, lines 45-47: Rather than a 4-6 hour delay, I think the Fig 3 residual panels (except Campbell River) suggest a broader peak for the model. 
Look in closer detail...

16.	Page 19, lines 39-52: Though you may have seen it already, I think another potentially useful reference for surges entering from the Pacific is Thomson et al. (JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 112, C09022, doi:10.1029/2006JC003925, 2007) In their Fig 6 note the numerous short interval, estuarine reversals that arise in Jan – Mar. It would be interesting to know if these events corresponded to surges at the 4 tide gauges you used to evaluate your model. Though beyond the scope of this paper (but probably something you have thought of already), it would be interesting to investigate how this Pacific signal moves up Juan de Fuca and enters Georgia.
Look this and possibly add as a reference

17.	Page 19, line 58 through 1st paragraph of page 20: Of course, this interaction is probably even more important in the shallow regions around the Richmond dikes and Boundary Bay, where you are not evaluating the model. But as you acknowledge, to do well there you will need wetting-and-drying.
Comments on this further?

18.	Page 20, lines 30-32: As remarked in point 3 above, it is therefore important to know how well your grid has represented these channels.
More details on grid... Perhaps Susan can add some comments about how grid smoothing was affected this area.

19.	Fig 6: Could you adjust the colour legend so the sea surface height in Juan de Fuca is more apparent? It is presently difficult to see any eastward propagation. Is there any; i.e., was the Pacific boundary forcing as important in this case? Given your Tofino vs Neah Bay comments on page 21 (lines 41-45), I guess it should have been.
Figure can be adjusted. 

20.	Page 22, line 58: Though you suggest it may be important in this case, it would be interesting to know in the other cases how much influence the Johnstone Strait boundary forcing has, relative to the Juan de Fuca forcing.  Does the sea surface height anomaly at Port Hardy relative to Tofino (or Neah Bay) determine this (e.g.,  2nd panel in Fig 10)? 
Could do a test case with PH forcing off..? I don't think PH is important. I think we get reflection in Jonstone Strait.

21.	Fig 11: Just to be clear, do these wind directions specify where the wind is headed or where it is from? The major improvement in the high vs low resolution winds at Point Atkinson seems to be when the direction is around 180 degrees. If this direction means toward the west then it is telling us that the high resolution model is getting Howe Sound outflow winds more accurately.
Can clarify.

22.	Fig 11 and associated text: Given the relative importance of local vs remote forcing, I think it would be interesting to evaluate the 2 atmospheric models with observations from the NOAA buoy at the entrance to Juan de Fuca (http://www.ndbc.noaa.gov/station_page.php?station=46087). Some of the high resolution models I have seen covering this region don’t get the along-strait wind directions correctly.
This can be added.

23.	Page 29, line 52: I assume the eventual aim is to obtain your Juan de Fuca (and Johnstone?) boundary forcing from the North Pacific NEMO model under development by Youyu Lu and colleagues. If so, it will be important to assimilate data nearby to ensure as much accuracy as possible.
Not sure how to comment on this...
